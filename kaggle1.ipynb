{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# pd.options.mode.use_inf_as_na = True\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_column(column_data):\n",
    "    x = column_data.values.astype(float) #returns a numpy array\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    return x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "train_data_copy = train_data.copy()\n",
    "test_data = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop(columns = ['Id','Street', 'Utilities', 'PoolQC'], inplace = True)\n",
    "test_with_id = test_data.copy()\n",
    "test_data.drop(columns = ['Id','Street', 'Utilities', 'PoolQC'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data:\n",
    "# - Convert categorical to one-hot representation\n",
    "# - NaN\n",
    "for column in test_data.columns:\n",
    "    if test_data[column].dtype == object:\n",
    "        # Need to do one-hot encoding\n",
    "        new_col = pd.get_dummies(test_data[column].astype(str), dummy_na = False, prefix=column, prefix_sep='_')\n",
    "        test_data.drop(columns = column, inplace = True)\n",
    "        test_data = pd.concat([test_data, new_col], axis =1)\n",
    "    else:\n",
    "        #normalize\n",
    "        test_data[column] = norm_column(test_data[[column]])\n",
    "        # check NaN value\n",
    "#         if any(train_data[column].isnull()): # replace NaN with median\n",
    "        median = test_data[~test_data[column].isnull()][column].median()\n",
    "#         train_data[column] = train_data[column].fillna(median)\n",
    "        test_data[column].fillna(median, inplace = True)\n",
    "        #Check inf values\n",
    "#         if any(np.isinf(train_data[column])): # replace inf with max and -inf with min\n",
    "#             max_ = train_data[column].max()\n",
    "#             min_ = train_data[column].min()\n",
    "#             train_data[column].replace([np.inf, -np.inf], [max_, min_], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in train_data.columns:\n",
    "    if train_data[column].dtype == object:\n",
    "        # Need to do one-hot encoding\n",
    "        new_col = pd.get_dummies(train_data[column].astype(str), dummy_na = False, prefix=column, prefix_sep='_')\n",
    "        train_data.drop(columns = column, inplace = True)\n",
    "        train_data = pd.concat([train_data, new_col], axis =1)\n",
    "    else:\n",
    "        if column != 'SalePrice':\n",
    "            #normalize\n",
    "            train_data[column] = norm_column(train_data[[column]])\n",
    "            # check NaN value\n",
    "    #         if any(train_data[column].isnull()): # replace NaN with median\n",
    "        median = train_data[~train_data[column].isnull()][column].median()\n",
    "    #         train_data[column] = train_data[column].fillna(median)\n",
    "        train_data[column].fillna(median, inplace = True)\n",
    "        #Check inf values\n",
    "#         if any(np.isinf(train_data[column])): # replace inf with max and -inf with min\n",
    "#             max_ = train_data[column].max()\n",
    "#             min_ = train_data[column].min()\n",
    "#             train_data[column].replace([np.inf, -np.inf], [max_, min_], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in train_data.columns:\n",
    "#     if(any(train_data[column].isnull())):\n",
    "#         print(train_data[column])\n",
    "# # len(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in train_data.columns:\n",
    "#     if (any(train_data[column].isnull())):\n",
    "#         print(column)\n",
    "#     if (any(np.isinf(train_data[column]))):\n",
    "#         print('Inf!!!!' + column)\n",
    "#     if (any(np.isinf(-train_data[column]))):\n",
    "#         print('-Inf!!!!' + column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'one_hot_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-aa64774803f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Treat NaN and inf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Check percentages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mone_hot_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LotFrontage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mone_hot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m# too many we will not drop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mone_hot_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'pearson'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'LotFrontage'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Treat NaN and inf\n",
    "# Check percentages\n",
    "len(one_hot_data[one_hot_data['LotFrontage'].isnull()])/len(one_hot_data)\n",
    "# too many we will not drop\n",
    "a = one_hot_data.corr(method ='pearson')['LotFrontage']\n",
    "a[(a>0.5) | (a< -0.5)]\n",
    "# No correlation with other columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_data.drop(columns= ['SalePrice']), train_data[['SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = list(set(x_train.columns) - set(test_data.columns))\n",
    "for item in diff:\n",
    "    test_data[item] = 0\n",
    "    \n",
    "diff = list(set(test_data.columns) - set(x_train.columns))\n",
    "test_data = test_data.drop(columns= diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 296)\n",
      "(1459, 296)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rr = Ridge(alpha=0.01) # higher the alpha value, more restriction on the coefficients; low alpha > more generalization, coefficients are barely\n",
    "# restricted and in this case linear and ridge regression resembles\n",
    "rr.fit(x_train, y_train)\n",
    "# Ridge_train_score = rr.score(x_train,y_train)\n",
    "print(x_train.shape)\n",
    "print(test_data.shape)\n",
    "prediction = rr.predict(test_data).T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = test_with_id['Id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Id': ids, 'SalePrice': prediction})\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
